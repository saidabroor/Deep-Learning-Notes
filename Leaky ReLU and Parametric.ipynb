{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02dc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLU - If x is greater than 0, then output is x, else it is 0.\n",
    "\n",
    "If too many outputs become 0, the neuron stops learning = Dead Neuron Problem\n",
    "\n",
    "Leaky ReLu - small slope for negative values\n",
    "instead of putting 0 for negatives, it outputs something like 0.01 * x\n",
    "  \n",
    "Parametric ReLu - the same as Leaky Relu with small slope but in Leaky ReLU, small slope is fixed but in Parametric ReLU, it is learned by the network\n",
    "\n",
    "\n",
    "Disadvantages:\n",
    "- not zero centred (meaning that weight updation is not happening efficiently)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
